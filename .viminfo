# This viminfo file was generated by Vim 8.2.
# You may edit it if you're careful!

# Viminfo version
|1,4

# Value of 'encoding' when this file was written
*encoding=utf-8


# hlsearch on (H) or off (h):
~h
# Last Search Pattern:
~MSle0~/bin

# Command Line History (newest to oldest):
:wq!
|2,0,1753996023,,"wq!"
:wq
|2,0,1753996020,,"wq"
:q
|2,0,1753995341,,"q"
:!wq
|2,0,1753995320,,"!wq"
::
|2,0,1753995285,,":"
:q!
|2,0,1753993595,,"q!"
:.,.+77!set -e
|2,0,1753993585,,".,.+77!set -e"

# Search String History (newest to oldest):
?/bin/bash
|2,1,1753993784,47,"bin/bash"
? \.\.\."
|2,1,1753993585,,"\\.\\.\\.\""

# Expression History (newest to oldest):

# Input Line History (newest to oldest):

# Debug Line History (newest to oldest):

# Registers:
""1	LINE	0
	    echo "Model files:"
	    ls -la $MODEL_PATH | grep -E "safetensors|bin|json" | head -5
	    echo "..."
	    echo "Total safetensors files: $(ls $MODEL_PATH/*.safetensors 2>/dev/null | wc -l)"
	    
	    if [ -f "$MODEL_PATH/config.json" ]; then
	        echo ""
	        echo "Model configuration:"
	        python -c "
	import json
	with open('$MODEL_PATH/config.json', 'r') as f:
	    config = json.load(f)
	    print(f'  Model type: {config.get(\"model_type\", \"unknown\")}')
	    print(f'  Hidden size: {config.get(\"hidden_size\", \"unknown\")}')
	    print(f'  Num layers: {config.get(\"num_hidden_layers\", \"unknown\")}')
	    print(f'  Num attention heads: {config.get(\"num_attention_heads\", \"unknown\")}')
	    print(f'  Max position embeddings: {config.get(\"max_position_embeddings\", \"unknown\")}')
	    print(f'  Vocab size: {config.get(\"vocab_size\", \"unknown\")}')
	    print(f'  Quantization: {config.get(\"quantization_config\", {}).get(\"bits\", \"none\")}')
	" 2>/dev/null
	    fi
	else
	    echo -e "${RED}Model directory not found at $MODEL_PATH${NC}"
	fi
	
	# 8. RUNNING PROCESSES
	section "RUNNING PROCESSES"
	echo "vLLM processes:"
	ps aux | grep -E "vllm|llm" | grep -v grep || echo "  None found"
	echo ""
	echo "Python processes:"
	ps aux | grep python | grep -v grep | head -5 || echo "  None found"
	
	# 9. SCREEN SESSIONS
	section "SCREEN SESSIONS"
	screen -ls 2>/dev/null || echo "No screen sessions found"
	
	# 10. VLLM LOGS
	section "RECENT VLLM LOGS"
	echo "Available log files:"
	ls -lah /root/vllm*.log 2>/dev/null | tail -5 || echo "  No log files found"
	
	if [ -f "/root/vllm_pipeline.log" ]; then
	    echo ""
	    echo "Last error in pipeline log:"
	    grep -E "ERROR|ValueError|RuntimeError" /root/vllm_pipeline.log | tail -3
	    echo ""
	    echo "Memory info from pipeline log:"
	    grep -E "Available KV cache|estimated maximum model length" /root/vllm_pipeline.log | tail -3
	fi
|3,1,1,1,50,0,1753996017,"    echo \"Model files:\"","    ls -la $MODEL_PATH | grep -E \"safetensors|bin|json\" | head -5","    echo \"...\"","    echo \"Total safetensors files: $(ls $MODEL_PATH/*.safetensors 2>/dev/null | wc -l)\"","    ","    if [ -f \"$MODEL_PATH/config.json\" ]; then","        echo \"\"","        echo \"Model configuration:\"","        python -c \"","import json","with open('$MODEL_PATH/config.json', 'r') as f:",>27
|<"    config = json.load(f)","    print(f'  Model type: {config.get(\\\"model_type\\\", \\\"unknown\\\")}')","    print(f'  Hidden size: {config.get(\\\"hidden_size\\\", \\\"unknown\\\")}')","    print(f'  Num layers: {config.get(\\\"num_hidden_layers\\\", \\\"unknown\\\")}')","    print(f'  Num attention heads: {config.get(\\\"num_attention_heads\\\", \\\"unknown\\\")}')","    print(f'  Max position embeddings: {config.get(\\\"max_position_embeddings\\\", \\\"unknown\\\")}')",>79
|<"    print(f'  Vocab size: {config.get(\\\"vocab_size\\\", \\\"unknown\\\")}')","    print(f'  Quantization: {config.get(\\\"quantization_config\\\", {}).get(\\\"bits\\\", \\\"none\\\")}')","\" 2>/dev/null","    fi","else","    echo -e \"${RED}Model directory not found at $MODEL_PATH${NC}\"","fi","","# 8. RUNNING PROCESSES","section \"RUNNING PROCESSES\"","echo \"vLLM processes:\"","ps aux | grep -E \"vllm|llm\" | grep -v grep || echo \"  None found\"","echo \"\"",>28
|<"echo \"Python processes:\"","ps aux | grep python | grep -v grep | head -5 || echo \"  None found\"","","# 9. SCREEN SESSIONS","section \"SCREEN SESSIONS\"","screen -ls 2>/dev/null || echo \"No screen sessions found\"","","# 10. VLLM LOGS","section \"RECENT VLLM LOGS\"","echo \"Available log files:\"","ls -lah /root/vllm*.log 2>/dev/null | tail -5 || echo \"  No log files found\"","","if [ -f \"/root/vllm_pipeline.log\" ]; then","    echo \"\"",>42
|<"    echo \"Last error in pipeline log:\"","    grep -E \"ERROR|ValueError|RuntimeError\" /root/vllm_pipeline.log | tail -3","    echo \"\"","    echo \"Memory info from pipeline log:\"","    grep -E \"Available KV cache|estimated maximum model length\" /root/vllm_pipeline.log | tail -3","fi"
"2	LINE	0
	#!/bin/bash
	# Comprehensive vLLM System Fingerprint Script
	# This script collects all relevant information about the vLLM setup
	
	echo "==============================================="
	echo "     vLLM SYSTEM FINGERPRINT REPORT"
	echo "     Generated: $(date)"
	echo "==============================================="
	
	# Colors for output
	RED='\033[0;31m'
	GREEN='\033[0;32m'
	YELLOW='\033[1;33m'
	BLUE='\033[0;34m'
	NC='\033[0m'
	
	section() {
	    echo ""
	    echo -e "${BLUE}=== $1 ===${NC}"
	    echo "----------------------------------------"
	}
	
	# 1. SYSTEM BASICS
	section "SYSTEM INFORMATION"
	echo "Hostname: $(hostname)"
	echo "OS: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
	echo "Kernel: $(uname -r)"
	echo "CPU: $(lscpu | grep 'Model name' | cut -d':' -f2 | xargs)"
	echo "CPU Cores: $(nproc)"
	echo "Total RAM: $(free -h | grep Mem | awk '{print $2}')"
	echo "Available RAM: $(free -h | grep Mem | awk '{print $7}')"
	
	# 2. GPU INFORMATION
	section "GPU CONFIGURATION"
	nvidia-smi --query-gpu=index,name,memory.total,memory.free,temperature.gpu,power.draw --format=csv,noheader,nounits | while read line; do
	    echo "GPU $line"
	done
	echo ""
	echo "CUDA Version: $(nvidia-smi | grep "CUDA Version" | awk '{print $9}')"
	echo "Driver Version: $(nvidia-smi | grep "Driver Version" | awk '{print $3}')"
	
	# 3. PYTHON ENVIRONMENT
	section "PYTHON ENVIRONMENT"
	source /opt/vllm/bin/activate 2>/dev/null
	echo "Python: $(python --version 2>&1)"
	echo "Python Path: $(which python)"
	echo "Pip: $(pip --version)"
	
	# 4. KEY PACKAGES
	section "ML PACKAGES"
|3,0,2,1,50,0,1753996014,"#!/bin/bash","# Comprehensive vLLM System Fingerprint Script","# This script collects all relevant information about the vLLM setup","","echo \"===============================================\"","echo \"     vLLM SYSTEM FINGERPRINT REPORT\"","echo \"     Generated: $(date)\"","echo \"===============================================\"","","# Colors for output","RED='\\033[0;31m'","GREEN='\\033[0;32m'","YELLOW='\\033[1;33m'",>20
|<"BLUE='\\033[0;34m'","NC='\\033[0m'","","section() {","    echo \"\"","    echo -e \"${BLUE}=== $1 ===${NC}\"","    echo \"----------------------------------------\"","}","","# 1. SYSTEM BASICS","section \"SYSTEM INFORMATION\"","echo \"Hostname: $(hostname)\"","echo \"OS: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'\"' -f2)\"","echo \"Kernel: $(uname -r)\"","echo \"CPU: $(lscpu | grep 'Model name' | cut -d':' -f2 | xargs)\"","echo \"CPU Cores: $(nproc)\"",>62
|<"echo \"Total RAM: $(free -h | grep Mem | awk '{print $2}')\"","echo \"Available RAM: $(free -h | grep Mem | awk '{print $7}')\"","","# 2. GPU INFORMATION","section \"GPU CONFIGURATION\"","nvidia-smi --query-gpu=index,name,memory.total,memory.free,temperature.gpu,power.draw --format=csv,noheader,nounits | while read line; do","    echo \"GPU $line\"","done","echo \"\"","echo \"CUDA Version: $(nvidia-smi | grep \"CUDA Version\" | awk '{print $9}')\"",>85
|<"echo \"Driver Version: $(nvidia-smi | grep \"Driver Version\" | awk '{print $3}')\"","","# 3. PYTHON ENVIRONMENT","section \"PYTHON ENVIRONMENT\"","source /opt/vllm/bin/activate 2>/dev/null","echo \"Python: $(python --version 2>&1)\"","echo \"Python Path: $(which python)\"","echo \"Pip: $(pip --version)\"","","# 4. KEY PACKAGES","section \"ML PACKAGES\""
"3	LINE	0
	# Create a comprehensive fingerprint script
	cat > /root/system_check.sh << 'EOF'
	#!/bin/bash
	
	echo "=== Python Environment Check ==="
	source /opt/vllm/bin/activate
	
	echo "Python packages related to vLLM and ML:"
	pip list | grep -E "vllm|torch|transformers|numpy|cuda|flash|triton|xformers" | sort
	
	echo -e "\n=== vLLM Installation Details ==="
	python -c "
	import vllm
	import os
	print(f'vLLM version: {vllm.__version__}')
	print(f'vLLM location: {vllm.__file__}')
	print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')
	"
	
	echo -e "\n=== Model Details ==="
	echo "Model directory contents:"
	ls -lah /models/qwen3/ | head -20
	
	echo -e "\nModel size:"
	du -sh /models/qwen3/
	
	echo -e "\nModel config.json:"
	cat /models/qwen3/config.json | python -m json.tool | head -30
	
	echo -e "\n=== System Libraries ==="
	echo "CUDA libraries:"
	ldconfig -p | grep cuda | head -10
	
	echo -e "\nNCCL version:"
	python -c "import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')"
	
	echo -e "\n=== GPU Details ==="
	python -c "
	import torch
	for i in range(torch.cuda.device_count()):
	    props = torch.cuda.get_device_properties(i)
	    print(f'GPU {i}: {props.name}')
	    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')
	    print(f'  Compute Capability: {props.major}.{props.minor}')
	"
	
	echo -e "\n=== vLLM Configuration Check ==="
	python -c "
	try:
	    from vllm.config import ModelConfig
|3,0,3,1,50,0,1753995449,"# Create a comprehensive fingerprint script","cat > /root/system_check.sh << 'EOF'","#!/bin/bash","","echo \"=== Python Environment Check ===\"","source /opt/vllm/bin/activate","","echo \"Python packages related to vLLM and ML:\"","pip list | grep -E \"vllm|torch|transformers|numpy|cuda|flash|triton|xformers\" | sort","","echo -e \"\\n=== vLLM Installation Details ===\"","python -c \"","import vllm","import os",>44
|<"print(f'vLLM version: {vllm.__version__}')","print(f'vLLM location: {vllm.__file__}')","print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')","\"","","echo -e \"\\n=== Model Details ===\"","echo \"Model directory contents:\"","ls -lah /models/qwen3/ | head -20","","echo -e \"\\nModel size:\"","du -sh /models/qwen3/","","echo -e \"\\nModel config.json:\"","cat /models/qwen3/config.json | python -m json.tool | head -30","","echo -e \"\\n=== System Libraries ===\"",>26
|<"echo \"CUDA libraries:\"","ldconfig -p | grep cuda | head -10","","echo -e \"\\nNCCL version:\"","python -c \"import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')\"","","echo -e \"\\n=== GPU Details ===\"","python -c \"","import torch","for i in range(torch.cuda.device_count()):","    props = torch.cuda.get_device_properties(i)","    print(f'GPU {i}: {props.name}')","    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')",>65
|<"    print(f'  Compute Capability: {props.major}.{props.minor}')","\"","","echo -e \"\\n=== vLLM Configuration Check ===\"","python -c \"","try:","    from vllm.config import ModelConfig"
"4	LINE	0
	# Create a comprehensive fingerprint script
	cat > /root/system_check.sh << 'EOF'
	#!/bin/bash
	
	echo "=== Python Environment Check ==="
	source /opt/vllm/bin/activate
	
	echo "Python packages related to vLLM and ML:"
	pip list | grep -E "vllm|torch|transformers|numpy|cuda|flash|triton|xformers" | sort
	
	echo -e "\n=== vLLM Installation Details ==="
	python -c "
	import vllm
	import os
	print(f'vLLM version: {vllm.__version__}')
	print(f'vLLM location: {vllm.__file__}')
	print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')
	"
	
	echo -e "\n=== Model Details ==="
	echo "Model directory contents:"
	ls -lah /models/qwen3/ | head -20
	
	echo -e "\nModel size:"
	du -sh /models/qwen3/
	
	echo -e "\nModel config.json:"
	cat /models/qwen3/config.json | python -m json.tool | head -30
	
	echo -e "\n=== System Libraries ==="
	echo "CUDA libraries:"
	ldconfig -p | grep cuda | head -10
	
	echo -e "\nNCCL version:"
	python -c "import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')"
	
	echo -e "\n=== GPU Details ==="
	python -c "
	import torch
	for i in range(torch.cuda.device_count()):
	    props = torch.cuda.get_device_properties(i)
	    print(f'GPU {i}: {props.name}')
	    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')
	    print(f'  Compute Capability: {props.major}.{props.minor}')
	"
	
	echo -e "\n=== vLLM Configuration Check ==="
	python -c "
	try:
	    from vllm.config import ModelConfig
|3,0,4,1,50,0,1753995374,"# Create a comprehensive fingerprint script","cat > /root/system_check.sh << 'EOF'","#!/bin/bash","","echo \"=== Python Environment Check ===\"","source /opt/vllm/bin/activate","","echo \"Python packages related to vLLM and ML:\"","pip list | grep -E \"vllm|torch|transformers|numpy|cuda|flash|triton|xformers\" | sort","","echo -e \"\\n=== vLLM Installation Details ===\"","python -c \"","import vllm","import os",>44
|<"print(f'vLLM version: {vllm.__version__}')","print(f'vLLM location: {vllm.__file__}')","print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')","\"","","echo -e \"\\n=== Model Details ===\"","echo \"Model directory contents:\"","ls -lah /models/qwen3/ | head -20","","echo -e \"\\nModel size:\"","du -sh /models/qwen3/","","echo -e \"\\nModel config.json:\"","cat /models/qwen3/config.json | python -m json.tool | head -30","","echo -e \"\\n=== System Libraries ===\"",>26
|<"echo \"CUDA libraries:\"","ldconfig -p | grep cuda | head -10","","echo -e \"\\nNCCL version:\"","python -c \"import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')\"","","echo -e \"\\n=== GPU Details ===\"","python -c \"","import torch","for i in range(torch.cuda.device_count()):","    props = torch.cuda.get_device_properties(i)","    print(f'GPU {i}: {props.name}')","    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')",>65
|<"    print(f'  Compute Capability: {props.major}.{props.minor}')","\"","","echo -e \"\\n=== vLLM Configuration Check ===\"","python -c \"","try:","    from vllm.config import ModelConfig"
"5	LINE	0
	# Create a comprehensive fingerprint script
	cat > /root/system_check.sh << 'EOF'
	#!/bin/bash
	
	echo "=== Python Environment Check ==="
	source /opt/vllm/bin/activate
	
	echo "Python packages related to vLLM and ML:"
	pip list | grep -E "vllm|torch|transformers|numpy|cuda|flash|triton|xformers" | sort
	
	echo -e "\n=== vLLM Installation Details ==="
	python -c "
	import vllm
	import os
	print(f'vLLM version: {vllm.__version__}')
	print(f'vLLM location: {vllm.__file__}')
	print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')
	"
	
	echo -e "\n=== Model Details ==="
	echo "Model directory contents:"
	ls -lah /models/qwen3/ | head -20
	
	echo -e "\nModel size:"
	du -sh /models/qwen3/
	
	echo -e "\nModel config.json:"
	cat /models/qwen3/config.json | python -m json.tool | head -30
	
	echo -e "\n=== System Libraries ==="
	echo "CUDA libraries:"
	ldconfig -p | grep cuda | head -10
	
	echo -e "\nNCCL version:"
	python -c "import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')"
	
	echo -e "\n=== GPU Details ==="
	python -c "
	import torch
	for i in range(torch.cuda.device_count()):
	    props = torch.cuda.get_device_properties(i)
	    print(f'GPU {i}: {props.name}')
	    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')
	    print(f'  Compute Capability: {props.major}.{props.minor}')
	"
	
	echo -e "\n=== vLLM Configuration Check ==="
	python -c "
	try:
	    from vllm.config import ModelConfig
|3,0,5,1,50,0,1753995336,"# Create a comprehensive fingerprint script","cat > /root/system_check.sh << 'EOF'","#!/bin/bash","","echo \"=== Python Environment Check ===\"","source /opt/vllm/bin/activate","","echo \"Python packages related to vLLM and ML:\"","pip list | grep -E \"vllm|torch|transformers|numpy|cuda|flash|triton|xformers\" | sort","","echo -e \"\\n=== vLLM Installation Details ===\"","python -c \"","import vllm","import os",>44
|<"print(f'vLLM version: {vllm.__version__}')","print(f'vLLM location: {vllm.__file__}')","print(f'vLLM install dir: {os.path.dirname(vllm.__file__)}')","\"","","echo -e \"\\n=== Model Details ===\"","echo \"Model directory contents:\"","ls -lah /models/qwen3/ | head -20","","echo -e \"\\nModel size:\"","du -sh /models/qwen3/","","echo -e \"\\nModel config.json:\"","cat /models/qwen3/config.json | python -m json.tool | head -30","","echo -e \"\\n=== System Libraries ===\"",>26
|<"echo \"CUDA libraries:\"","ldconfig -p | grep cuda | head -10","","echo -e \"\\nNCCL version:\"","python -c \"import torch; print(f'NCCL version: {torch.cuda.nccl.version()}')\"","","echo -e \"\\n=== GPU Details ===\"","python -c \"","import torch","for i in range(torch.cuda.device_count()):","    props = torch.cuda.get_device_properties(i)","    print(f'GPU {i}: {props.name}')","    print(f'  Memory: {props.total_memory / 1024**3:.1f} GB')",>65
|<"    print(f'  Compute Capability: {props.major}.{props.minor}')","\"","","echo -e \"\\n=== vLLM Configuration Check ===\"","python -c \"","try:","    from vllm.config import ModelConfig"
"6	LINE	0
	EOF
|3,0,6,1,1,0,1753995323,"EOF"
"7	LINE	0
	./root/system_check.sh
|3,0,7,1,1,0,1753995296,"./root/system_check.sh"
"8	LINE	0
	chmod +x /root/system_check.sh
|3,0,8,1,1,0,1753995296,"chmod +x /root/system_check.sh"
"9	LINE	0
	
|3,0,9,1,1,0,1753995295,""
"-	CHAR	0
	h
|3,0,36,0,1,0,1753993585,"h"

# File marks:
'0  336  54  ~/fp.sh
|4,48,336,54,1753996023,"~/fp.sh"
'1  1  53  ~/fp.sh
|4,49,1,53,1753995503,"~/fp.sh"
'2  193  53  ~/fp.sh
|4,50,193,53,1753995503,"~/fp.sh"
'3  1  21  ~/fp.sh
|4,51,1,21,1753995387,"~/fp.sh"
'4  1  21  ~/fp.sh
|4,52,1,21,1753995387,"~/fp.sh"
'5  1  21  ~/fp.sh
|4,53,1,21,1753995387,"~/fp.sh"
'6  73  21  ~/fp.sh
|4,54,73,21,1753995387,"~/fp.sh"
'7  1  21  ~/fp.sh
|4,55,1,21,1753995346,"~/fp.sh"
'8  1  21  ~/fp.sh
|4,56,1,21,1753995346,"~/fp.sh"
'9  1  21  ~/fp.sh
|4,57,1,21,1753995346,"~/fp.sh"

# Jumplist (newest first):
-'  336  54  ~/fp.sh
|4,39,336,54,1753996023,"~/fp.sh"
-'  1  53  ~/fp.sh
|4,39,1,53,1753996013,"~/fp.sh"
-'  193  53  ~/fp.sh
|4,39,193,53,1753995503,"~/fp.sh"
-'  1  21  ~/fp.sh
|4,39,1,21,1753995440,"~/fp.sh"
-'  73  21  ~/fp.sh
|4,39,73,21,1753995387,"~/fp.sh"
-'  1  21  ~/fp.sh
|4,39,1,21,1753995372,"~/fp.sh"
-'  73  21  ~/fp.sh
|4,39,73,21,1753995346,"~/fp.sh"
-'  1  0  ~/fp.sh
|4,39,1,0,1753995334,"~/fp.sh"
-'  41  36  ~/fp.sh
|4,39,41,36,1753995173,"~/fp.sh"
-'  1  167  ~/fp.sh
|4,39,1,167,1753995169,"~/fp.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  107  68  ~/p.sh
|4,39,107,68,1753994262,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  1  0  ~/p.sh
|4,39,1,0,1753994261,"~/p.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"
-'  238  47  ~/so.sh
|4,39,238,47,1753993789,"~/so.sh"

# History of marks within files (newest to oldest):

> ~/fp.sh
	*	1753996020	0
	"	336	54
	^	336	55
	.	336	54
	+	1	167
	+	1	36
	+	1	43
	+	1	21
	+	1	43
	+	1	11
	+	1	53
	+	1	11
	+	336	54

> ~/p.sh
	*	1753994261	0
	"	107	68
	^	107	69
	.	107	68
	+	107	68

> ~/so.sh
	*	1753993788	0
	"	238	47
	^	238	48
	.	238	48
	+	1	41
	+	1	0
	+	1	5
	+	1	40
	+	1	31
	+	1	40
	+	238	48

> ~/start2.sh
	*	1753993360	0
	"	125	41
	^	125	42
	.	125	41
	+	125	41

> ~/start.sh
	*	1753992772	0
	"	64	31
	^	64	32
	.	64	31
	+	64	31

> ~/v.sh
	*	1753992241	0
	"	33	17
	^	33	18
	.	33	18
	+	1	51
	+	33	18

> ~/u.sh
	*	1753992096	0
	"	36	20
	^	37	0
	.	36	21
	+	36	21

> ~/u
	*	1753992071	0
	"	1	0

> ~/t.sh
	*	1753988428	0
	"	41	18
	^	41	19
	.	41	18
	+	41	18

> ~/s.sh
	*	1753988289	0
	"	57	36
	^	57	37
	.	57	36
	+	57	36
